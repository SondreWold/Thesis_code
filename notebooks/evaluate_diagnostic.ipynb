{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,accuracy_score, matthews_corrcoef, confusion_matrix\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://huggingface.co/api/models/roberta-base-whole-word-masking",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f7396f4a3166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"roberta-base-whole-word-masking\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/in4080/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1653\u001b[0m                 \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m                 \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m             )\n\u001b[1;32m   1657\u001b[0m             additional_files_names = {\n",
      "\u001b[0;32m~/anaconda3/envs/in4080/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mget_fast_tokenizer_file\u001b[0;34m(path_or_repo, revision, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   3461\u001b[0m     \u001b[0;31m# Inspect all files from the repo/folder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m     all_files = get_list_of_files(\n\u001b[0;32m-> 3463\u001b[0;31m         \u001b[0mpath_or_repo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m     )\n\u001b[1;32m   3465\u001b[0m     \u001b[0mtokenizer_files_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/in4080/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_list_of_files\u001b[0;34m(path_or_repo, revision, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1728\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m     model_info = HfApi(endpoint=HUGGINGFACE_CO_RESOLVE_ENDPOINT).model_info(\n\u001b[0;32m-> 1730\u001b[0;31m         \u001b[0mpath_or_repo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1731\u001b[0m     )\n\u001b[1;32m   1732\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfilename\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msiblings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/in4080/lib/python3.7/site-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mmodel_info\u001b[0;34m(self, repo_id, revision, token, timeout)\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n\u001b[1;32m    584\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mModelInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/in4080/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/api/models/roberta-base-whole-word-masking"
     ]
    }
   ],
   "source": [
    "tok = RobertaTokenizer.from_pretrained(\"roberta-base-whole-word-masking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on Glue Diagnostic, \"Ax\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scripts compares predictions on the Glue Diagnostic set against the gold labels. The script expects that the predictions are on the format: index\\tpredictions\\n\n",
    "\n",
    "That is:\n",
    "\n",
    "1 contradiction\n",
    "\n",
    "2 entailment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(predictions: pd.DataFrame, gold: pd.DataFrame = gold_df):\n",
    "    final = gold.copy()\n",
    "    final[\"prediction\"] = predictions[\"prediction\"]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_full(df_gold: pd.DataFrame, predictions_path: str):\n",
    "    predictions = get_dataframe(predictions_path)\n",
    "    final = merge_df(predictions, df_gold)\n",
    "    true_labels = list(final[\"Label\"])\n",
    "    pred_labels = list(final[\"prediction\"])\n",
    "    print(f\"MCC score: {matthews_corrcoef(true_labels, pred_labels)}\")\n",
    "    print(classification_report(true_labels, pred_labels, target_names=[\"contradiction\", \"neutral\", \"entailment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_common_sense(df_gold: pd.DataFrame, predictions_path: str):\n",
    "    predictions = get_dataframe(predictions_path)\n",
    "    final = merge_df(predictions, df_gold)\n",
    "    \n",
    "    knowledge = final[~final['Knowledge'].isnull()]\n",
    "    true_labels = list(knowledge[\"Label\"])\n",
    "    pred_labels = list(knowledge[\"prediction\"])\n",
    "    \n",
    "    knowledge_common = knowledge[knowledge.Knowledge.str.contains('Common',case=False)]\n",
    "    true_labels = list(knowledge_common[\"Label\"])\n",
    "    pred_labels = list(knowledge_common[\"prediction\"])\n",
    "\n",
    "    print(f\"MCC score: {matthews_corrcoef(true_labels, pred_labels)}\")\n",
    "    print(classification_report(true_labels, pred_labels, target_names=[\"contradiction\", \"neutral\", \"entailment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_wold_knowledge(df_gold: pd.DataFrame, predictions_path: str):\n",
    "    predictions = get_dataframe(predictions_path)\n",
    "    final = merge_df(predictions, df_gold)\n",
    "    \n",
    "    knowledge = final[~final['Knowledge'].isnull()]\n",
    "    true_labels = list(knowledge[\"Label\"])\n",
    "    pred_labels = list(knowledge[\"prediction\"])\n",
    "    \n",
    "    knowledge_world = knowledge[knowledge.Knowledge.str.contains('World',case=False)]\n",
    "    true_labels = list(knowledge_world[\"Label\"])\n",
    "    pred_labels = list(knowledge_world[\"prediction\"])\n",
    "\n",
    "    print(f\"MCC score: {matthews_corrcoef(true_labels, pred_labels)}\")\n",
    "    print(classification_report(true_labels, pred_labels, target_names=[\"contradiction\", \"neutral\", \"entailment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = get_dataframe(\"../data/diagnostic_gold.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full diagnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert base uncased, 3e5, 16 batch size, 3 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC score: 0.3715884275271643\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.56      0.52      0.54       258\n",
      "      neutral       0.63      0.75      0.69       460\n",
      "   entailment       0.56      0.45      0.50       386\n",
      "\n",
      "     accuracy                           0.59      1104\n",
      "    macro avg       0.58      0.58      0.58      1104\n",
      " weighted avg       0.59      0.59      0.59      1104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_full(gold, \"../diagnostic_results/bert_base_uncased_3e5_16_3/results_ax.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roberta base, 3e5, 16 batch size, 3 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC score: 0.41188796925134874\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.59      0.55      0.57       258\n",
      "      neutral       0.64      0.78      0.71       460\n",
      "   entailment       0.60      0.47      0.53       386\n",
      "\n",
      "     accuracy                           0.62      1104\n",
      "    macro avg       0.61      0.60      0.60      1104\n",
      " weighted avg       0.62      0.62      0.61      1104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_full(gold, \"../diagnostic_results/roberta_base_3e5_16_3/results_ax.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert base uncased, 3e5, 16 batch size, 3 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC score: 0.32741091196998096\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.68      0.52      0.59        58\n",
      "      neutral       0.60      0.50      0.54        56\n",
      "   entailment       0.39      0.64      0.48        36\n",
      "\n",
      "     accuracy                           0.54       150\n",
      "    macro avg       0.56      0.55      0.54       150\n",
      " weighted avg       0.58      0.54      0.55       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_common_sense(gold, \"../diagnostic_results/bert_base_uncased_3e5_16_3/results_ax.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roberta base, 3e5, 16 batch size, 3 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC score: 0.3708507737093856\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.65      0.48      0.55        58\n",
      "      neutral       0.62      0.59      0.61        56\n",
      "   entailment       0.46      0.69      0.56        36\n",
      "\n",
      "     accuracy                           0.57       150\n",
      "    macro avg       0.58      0.59      0.57       150\n",
      " weighted avg       0.60      0.57      0.57       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_common_sense(gold, \"../diagnostic_results/roberta_base_3e5_16_3/results_ax.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### World knowledge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert base uncased, 3e5, 16 batch size, 3 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC score: 0.13369507292599506\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.23      0.19      0.21        32\n",
      "      neutral       0.66      0.52      0.58        63\n",
      "   entailment       0.33      0.49      0.39        39\n",
      "\n",
      "     accuracy                           0.43       134\n",
      "    macro avg       0.41      0.40      0.39       134\n",
      " weighted avg       0.46      0.43      0.44       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_wold_knowledge(gold, \"../diagnostic_results/bert_base_uncased_3e5_16_3/results_ax.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roberta base, 3e5, 16 batch size, 3 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC score: 0.14983036699702876\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.24      0.16      0.19        32\n",
      "      neutral       0.66      0.56      0.60        63\n",
      "   entailment       0.33      0.51      0.40        39\n",
      "\n",
      "     accuracy                           0.45       134\n",
      "    macro avg       0.41      0.41      0.40       134\n",
      " weighted avg       0.46      0.45      0.45       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_wold_knowledge(gold, \"../diagnostic_results/roberta_base_3e5_16_3/results_ax.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bit1943f163d28f4bc9b7721f93b8953027"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
